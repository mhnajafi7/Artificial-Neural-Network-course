{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Assignment 1 - spring 2024\n",
        "\n",
        "### Mohammad Hossein Najafi - 97103938\n",
        "---\n",
        "We analyze the Hopfield network for memory association, and also work with the Self-Organizing Map (SOM) network in image segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prerequisites\n",
        "First, we import the numpy library because we use it to work with arrays as data. We also define a function for displaying fonts. Then, we define fonts with a 63 cell array (7*9 resolution) and display them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "BmJ3AljjVQP9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# definition of a function to display a font\n",
        "def show_font(font):\n",
        "    for pixel in np.arange(0, 63):\n",
        "        if pixel % 9 == 0:\n",
        "            print()\n",
        "        if font[pixel] == 1:\n",
        "            print(\"\\u2588\", end=\"\")\n",
        "        else:\n",
        "            print(\" \", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwyNpL_4VUNJ",
        "outputId": "0d8ed5d4-19aa-4625-baf0-044f8a159589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "████████ \n",
            "█       █\n",
            "█████████\n",
            "█       █\n",
            "█       █\n",
            "█       █\n",
            "████████ \n",
            "\n",
            "███████  \n",
            "█      █ \n",
            "█      █ \n",
            "████████ \n",
            "█      █ \n",
            "█      █ \n",
            "████████ \n",
            "\n",
            " ███████ \n",
            " █      █\n",
            " ███████ \n",
            " █      █\n",
            " █      █\n",
            " █      █\n",
            " ███████ "
          ]
        }
      ],
      "source": [
        "# Dataset of the letter B\n",
        "font_b_1=[\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 0\n",
        "]\n",
        "show_font(font_b_1)\n",
        "print()\n",
        "\n",
        "font_b_2=[\n",
        "    1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "    1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "    1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "    1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 0\n",
        "]\n",
        "show_font(font_b_2)\n",
        "\n",
        "print()\n",
        "font_b_3=[\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0\n",
        "]\n",
        "show_font(font_b_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ua7vgWVWJk",
        "outputId": "3fd477a9-57fa-4925-911d-4704e0f291de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ███████ \n",
            "█████████\n",
            "██       \n",
            "██       \n",
            "██       \n",
            "█████████\n",
            " ███████ \n",
            "\n",
            "██████   \n",
            "███████  \n",
            "██       \n",
            "██       \n",
            "██       \n",
            "███████  \n",
            "██████   \n",
            "\n",
            "█████████\n",
            "█████████\n",
            "██       \n",
            "██       \n",
            "██       \n",
            "█████████\n",
            "█████████"
          ]
        }
      ],
      "source": [
        "# Dataset of the letter C\n",
        "font_c_1 = [\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0\n",
        "]\n",
        "show_font(font_c_1)\n",
        "print()\n",
        "font_c_2 = [\n",
        "    1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "    1, 1, 1, 1, 1, 1, 0, 0, 0\n",
        "]\n",
        "show_font(font_c_2)\n",
        "print()\n",
        "font_c_3 = [\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1\n",
        "]\n",
        "show_font(font_c_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu-0tPAaVkwg",
        "outputId": "5dfce34c-a58a-49c3-97ae-c907e6543aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "█████████\n",
            "██      █\n",
            "██      █\n",
            "██      █\n",
            "██      █\n",
            "██      █\n",
            "█████████\n",
            "\n",
            "███████  \n",
            "██    ██ \n",
            "██    ██ \n",
            "██    ██ \n",
            "██    ██ \n",
            "██    ██ \n",
            "███████  \n",
            "\n",
            " ███████ \n",
            " ██    ██\n",
            " ██    ██\n",
            " ██    ██\n",
            " ██    ██\n",
            " ██    ██\n",
            " ███████ "
          ]
        }
      ],
      "source": [
        "# Dataset of the letter D\n",
        "font_d_1 = [\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1\n",
        "]\n",
        "show_font(font_d_1)\n",
        "print()\n",
        "\n",
        "font_d_2 = [\n",
        "    1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "    1, 1, 1, 1, 1, 1, 1, 0, 0\n",
        "]\n",
        "show_font(font_d_2)\n",
        "print()\n",
        "\n",
        "font_d_3 = [\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
        "    0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 1, 1, 1, 1, 1, 1, 1, 0\n",
        "]\n",
        "show_font(font_d_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-__PiZcVYm3",
        "outputId": "290f3c3f-fbd8-4310-db19-e5f3f9990e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " █       \n",
            " █       \n",
            " █       \n",
            " █       \n",
            " ██████  \n",
            "         \n",
            "         10\n",
            "\n",
            " █       \n",
            " █       \n",
            " █       \n",
            " █       \n",
            " █       \n",
            " █       \n",
            " █████   \n",
            "  █      \n",
            "  █      \n",
            "  █      \n",
            "  █      \n",
            "  █      \n",
            "  █      \n",
            "  ███████"
          ]
        }
      ],
      "source": [
        "# Dataset of the letter L\n",
        "font_l_1 = [\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "    0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 0, 0, 0, 0, 0, 0, 0\n",
        "]\n",
        "show_font(font_l_1)\n",
        "print(sum(font_l_1))\n",
        "\n",
        "font_l_2 = [\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "    0, 1, 1, 1, 1, 1, 0, 0, 0\n",
        "]\n",
        "show_font(font_l_2)\n",
        "\n",
        "font_l_3 = [\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "    0, 0, 1, 1, 1, 1, 1, 1, 1\n",
        "]\n",
        "show_font(font_l_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTQ-l7e9VgwC",
        "outputId": "8f6e9404-f16b-46b3-8f22-74aaba6cb0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "██      █\n",
            "█ █     █\n",
            "█  █    █\n",
            "█   █   █\n",
            "█    █  █\n",
            "█     █ █\n",
            "█      ██\n",
            "  █     █\n",
            "  ██    █\n",
            "  █ █   █\n",
            "  █  █  █\n",
            "  █   █ █\n",
            "  █    ██\n",
            "  █     █\n",
            "█     █  \n",
            "██    █  \n",
            "█ █   █  \n",
            "█  █  █  \n",
            "█   █ █  \n",
            "█    ██  \n",
            "█     █  "
          ]
        }
      ],
      "source": [
        "# Dataset of the letter N\n",
        "font_n_1 = [\n",
        "    1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
        "    1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
        "    1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
        "    1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
        "    1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
        "    1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
        "    1, 0, 0, 0, 0, 0, 0, 1, 1\n",
        "]\n",
        "show_font(font_n_1)\n",
        "\n",
        "font_n_2 = [\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
        "    0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
        "    0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
        "    0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "    0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
        "    0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
        "    0, 0, 1, 0, 0, 0, 0, 0, 1\n",
        "]\n",
        "show_font(font_n_2)\n",
        "\n",
        "font_n_3 = [\n",
        "    1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
        "    1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
        "    1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
        "    1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "    1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
        "    1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
        "    1, 0, 0, 0, 0, 0, 1, 0, 0\n",
        "]\n",
        "show_font(font_n_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Binary encoding\n",
        "Now, we defined the fonts, so without changing them (ther are binary definiton), create patterns with this 15 different fonts for 5 letters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "8iCbnQW3WMy2"
      },
      "outputs": [],
      "source": [
        "# Create the patterns array\n",
        "patterns = np.array([font_b_1, font_b_2, font_b_3, font_c_1, font_c_2, font_c_3, font_d_1, font_d_2, font_d_3, font_l_1, font_l_2, font_l_3, font_n_1, font_n_2, font_n_3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, define 5 different targets for 5 different neurons. As this is binary encoding, the target for each neuron corresponding to its letter is 1, and for others, it is 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "C8tSSJ6RThAg"
      },
      "outputs": [],
      "source": [
        "# Define binary target arrays where each array represents a neuron target class.\n",
        "# Each array has 15 elements with 1s at specific indices indicating the presence of the target.\n",
        "# The indices are as follows: 0-2: B, 3-5: C, 6-8: D, 9-11: L, 12-14: N\n",
        "target_b=[1,1,1, 0,0,0, 0,0,0, 0,0,0, 0,0,0]\n",
        "target_c=[0,0,0, 1,1,1, 0,0,0, 0,0,0, 0,0,0]\n",
        "target_d=[0,0,0, 0,0,0, 1,1,1, 0,0,0, 0,0,0]\n",
        "target_l=[0,0,0, 0,0,0, 0,0,0, 1,1,1, 0,0,0]\n",
        "target_n=[0,0,0, 0,0,0, 0,0,0, 0,0,0, 1,1,1]\n",
        "\n",
        "# Create a numpy array 'output_target' containing all the target arrays as rows.\n",
        "output_target= np.array([target_b,target_c,target_d,target_l,target_n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, we define a class that works like a Hebbian neuron model. First, it initializes the weights and bias based on the number of features. Then, with the given patterns, it trains and calculates the weights and bias. Finally, for a test case, it predicts the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iI3Fu7NWPYL",
        "outputId": "19aedf4a-8b70-4f16-bfda-be8155a8f78c"
      },
      "outputs": [],
      "source": [
        "# Define the Hebbian class for training the neurons and making predictions\n",
        "class Hebbian:\n",
        "    def __init__(self, num_features):\n",
        "        # Initialize weights and bias to zero\n",
        "        self.weights = [0.0] * num_features\n",
        "        self.bias = 0.0\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for i in range(len(X)):\n",
        "            # Update weights\n",
        "            for j in range(len(X[i])):\n",
        "                self.weights[j] += X[i][j] * y[i]\n",
        "\n",
        "            # Update bias\n",
        "            self.bias += y[i]\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i in range(len(X)):\n",
        "            # Calculate dot product of weights and input features\n",
        "            dot_product = sum(X[i][j] * self.weights[j] for j in range(len(X[i])))\n",
        "            # Add bias\n",
        "            y_in = dot_product + self.bias\n",
        "            # Make prediction\n",
        "            prediction = 1 if y_in >= 0 else -1  # Binary classification\n",
        "            predictions.append(prediction)\n",
        "        return predictions\n",
        "\n",
        "# Initialize the neurons with the number of features\n",
        "neuron_b = Hebbian(num_features=63)\n",
        "neuron_c = Hebbian(num_features=63)\n",
        "neuron_d = Hebbian(num_features=63)\n",
        "neuron_l = Hebbian(num_features=63)\n",
        "neuron_n = Hebbian(num_features=63)\n",
        "\n",
        "# Sample training data (features and labels)\n",
        "X_train = patterns # Features\n",
        "y_train = output_target # Labels\n",
        "\n",
        "# Train the models\n",
        "neuron_b.train(X_train, y_train[0])\n",
        "neuron_c.train(X_train, y_train[1])\n",
        "neuron_d.train(X_train, y_train[2])\n",
        "neuron_l.train(X_train, y_train[3])\n",
        "neuron_n.train(X_train, y_train[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample test data\n",
        "X_test = patterns\n",
        "\n",
        "# Make predictions\n",
        "predictions = np.zeros((5,15))\n",
        "predictions[0] = neuron_b.predict(X_test)\n",
        "predictions[1] = neuron_c.predict(X_test)\n",
        "predictions[2] = neuron_d.predict(X_test)\n",
        "predictions[3] = neuron_l.predict(X_test)\n",
        "predictions[4] = neuron_n.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 80.0 %\n",
            "Error rate for c: 80.0 %\n",
            "Error rate for d: 80.0 %\n",
            "Error rate for l: 80.0 %\n",
            "Error rate for n: 80.0 %\n",
            "\n",
            "Total error rate: 80.0 %\n"
          ]
        }
      ],
      "source": [
        "# show the predictions error rates for each letter\n",
        "print(\"Error rate for b:\",(1-np.mean(predictions[0] == target_b)) * 100, \"%\")\n",
        "print(\"Error rate for c:\",(1-np.mean(predictions[1] == target_c)) * 100, \"%\")\n",
        "print(\"Error rate for d:\",(1-np.mean(predictions[2] == target_d)) * 100, \"%\")\n",
        "print(\"Error rate for l:\",(1-np.mean(predictions[3] == target_l)) * 100, \"%\")\n",
        "print(\"Error rate for n:\",(1-np.mean(predictions[4] == target_n)) * 100, \"%\")\n",
        "print()\n",
        "print(\"Total error rate:\",(1-np.mean(predictions == output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With these results, we find that the binary encoding doesn't work correctly at all. An 80% error rate means it gives 15 outputs of 1. Except for the three fonts for its own letter, the outputs for the other fonts are 1 too, which is not good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bipolar encoding\n",
        "For bipolar encoding, it suffices to use a function that replaces zero arrays with -1 for patterns and targets. Then, train the neurons with these bipolar arrays and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYrQC6MLptca",
        "outputId": "4bb455e7-e8b6-43f5-e16b-da41f53a8675"
      },
      "outputs": [],
      "source": [
        "# Define a function to replace zeros with -1 in an array for bipolar encoding\n",
        "def replace_zero(array):\n",
        "  array = np.where(array==0,-1,array)\n",
        "  return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "yHGR0uyDat1V"
      },
      "outputs": [],
      "source": [
        "# Replace zeros with -1 in the patterns and output_target arrays\n",
        "bipolar_patterns = replace_zero(patterns)\n",
        "bipolar_output_target=replace_zero(output_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5NWn_jDk457",
        "outputId": "91d19750-0037-4756-f896-0ac9d230e09f"
      },
      "outputs": [],
      "source": [
        "# Initialize the neurons with the number of features\n",
        "bipolar_neuron_b = Hebbian(num_features=63)\n",
        "bipolar_neuron_c = Hebbian(num_features=63)\n",
        "bipolar_neuron_d = Hebbian(num_features=63)\n",
        "bipolar_neuron_l = Hebbian(num_features=63)\n",
        "bipolar_neuron_n = Hebbian(num_features=63)\n",
        "\n",
        "# Sample training data (features and labels)\n",
        "X_train = bipolar_patterns # Features\n",
        "y_train = bipolar_output_target # Labels\n",
        "\n",
        "# Train the models\n",
        "bipolar_neuron_b.train(X_train, y_train[0])\n",
        "bipolar_neuron_c.train(X_train, y_train[1])\n",
        "bipolar_neuron_d.train(X_train, y_train[2])\n",
        "bipolar_neuron_l.train(X_train, y_train[3])\n",
        "bipolar_neuron_n.train(X_train, y_train[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample test data\n",
        "X_test = bipolar_patterns\n",
        "\n",
        "predictions[0] = bipolar_neuron_b.predict(X_test)\n",
        "predictions[1] = bipolar_neuron_c.predict(X_test)\n",
        "predictions[2] = bipolar_neuron_d.predict(X_test)\n",
        "predictions[3] = bipolar_neuron_l.predict(X_test)\n",
        "predictions[4] = bipolar_neuron_n.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 13.33333333333333 %\n",
            "Error rate for c: 0.0 %\n",
            "Error rate for d: 19.999999999999996 %\n",
            "Error rate for l: 13.33333333333333 %\n",
            "Error rate for n: 0.0 %\n",
            "\n",
            "Total error rate: 9.333333333333337 %\n"
          ]
        }
      ],
      "source": [
        "# Calculate and print the error rate for each prediction\n",
        "print(\"Error rate for b:\", (1 - np.mean(predictions[0] == bipolar_output_target[0])) * 100, \"%\")\n",
        "print(\"Error rate for c:\", (1 - np.mean(predictions[1] == bipolar_output_target[1])) * 100, \"%\")\n",
        "print(\"Error rate for d:\", (1 - np.mean(predictions[2] == bipolar_output_target[2])) * 100, \"%\")\n",
        "print(\"Error rate for l:\", (1 - np.mean(predictions[3] == bipolar_output_target[3])) * 100, \"%\")\n",
        "print(\"Error rate for n:\", (1 - np.mean(predictions[4] == bipolar_output_target[4])) * 100, \"%\")\n",
        "print()\n",
        "\n",
        "# Calculate and print  error rate\n",
        "print(\"Total error rate:\", (1 - np.mean(predictions == bipolar_output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we see that bipolar encoding works much better than binary encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Noisy patterns (10%)\n",
        "To insert 10% noise into the pattern, we must change about 6 cells in each pattern. Therefore, we define a 15*6 array and assign it random numbers between zero and 63 to randomly select cells and modify them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "# Define the number of random indices to change\n",
        "number_of_random = 6\n",
        "\n",
        "# Randomly choose 6 indices to change and add 10% noise to the patterns\n",
        "indices_to_change = np.zeros((len(patterns),number_of_random))\n",
        "for i in range(len(patterns)):\n",
        "    indices_to_change[i] = random.sample(range(len(patterns[0])), number_of_random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create noisy patterns and noisy bipolar patterns                                         \n",
        "noisy_patterns = patterns.copy()\n",
        "noisy_bipolar_patterns = bipolar_patterns.copy()\n",
        "\n",
        "# Add noise to the patterns\n",
        "for i in range(len(patterns)):\n",
        "    for j in range(number_of_random):\n",
        "        if noisy_patterns[i][int(indices_to_change[i][j])] == 1:\n",
        "            noisy_patterns[i][int(indices_to_change[i][j])] = 0\n",
        "        else:\n",
        "            noisy_patterns[i][int(indices_to_change[i][j])] = 1\n",
        "\n",
        "# Add noise to the bipolar patterns\n",
        "for i in range(len(patterns)):\n",
        "    for j in range(number_of_random):\n",
        "        if noisy_bipolar_patterns[i][int(indices_to_change[i][j])] == 1:\n",
        "            noisy_bipolar_patterns[i][int(indices_to_change[i][j])] = -1\n",
        "        else:\n",
        "            noisy_bipolar_patterns[i][int(indices_to_change[i][j])] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions for the noisy patterns\n",
        "X_test = noisy_patterns\n",
        "predictions_for_noisy_patterns = np.zeros((5,15))\n",
        "\n",
        "predictions_for_noisy_patterns[0] = neuron_b.predict(X_test)\n",
        "predictions_for_noisy_patterns[1] = neuron_c.predict(X_test)\n",
        "predictions_for_noisy_patterns[2] = neuron_d.predict(X_test)\n",
        "predictions_for_noisy_patterns[3] = neuron_l.predict(X_test)\n",
        "predictions_for_noisy_patterns[4] = neuron_n.predict(X_test)\n",
        "\n",
        "# Make predictions for the noisy bipolar patterns\n",
        "X_test = noisy_bipolar_patterns\n",
        "predictions_for_noisy_bipolar_patterns = np.zeros((5,15))\n",
        "\n",
        "predictions_for_noisy_bipolar_patterns[0] = bipolar_neuron_b.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[1] = bipolar_neuron_c.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[2] = bipolar_neuron_d.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[3] = bipolar_neuron_l.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[4] = bipolar_neuron_n.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 80.0 %\n",
            "Error rate for c: 80.0 %\n",
            "Error rate for d: 80.0 %\n",
            "Error rate for l: 80.0 %\n",
            "Error rate for n: 80.0 %\n",
            "\n",
            "Total error rate for noisy patterns: 80.0 %\n"
          ]
        }
      ],
      "source": [
        "# Calculate and print the error rate for each prediction\n",
        "print(\"Error rate for b:\",(1-np.mean(predictions_for_noisy_patterns[0] == target_b)) * 100, \"%\")\n",
        "print(\"Error rate for c:\",(1-np.mean(predictions_for_noisy_patterns[1] == target_c)) * 100, \"%\")\n",
        "print(\"Error rate for d:\",(1-np.mean(predictions_for_noisy_patterns[2] == target_d)) * 100, \"%\")\n",
        "print(\"Error rate for l:\",(1-np.mean(predictions_for_noisy_patterns[3] == target_l)) * 100, \"%\")\n",
        "print(\"Error rate for n:\",(1-np.mean(predictions_for_noisy_patterns[4] == target_n)) * 100, \"%\")\n",
        "print()\n",
        "\n",
        "print(\"Total error rate for noisy patterns:\",(1-np.mean(predictions_for_noisy_patterns == output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For binary encoding, it still doesn't work correctly and shows neither improvement nor adverse effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 13.33333333333333 %\n",
            "Error rate for c: 0.0 %\n",
            "Error rate for d: 19.999999999999996 %\n",
            "Error rate for l: 19.999999999999996 %\n",
            "Error rate for n: 0.0 %\n",
            "\n",
            "Total error rate for noisy bipolar patterns: 10.666666666666668 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Error rate for b:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[0] == bipolar_output_target[0])) * 100, \"%\")\n",
        "print(\"Error rate for c:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[1] == bipolar_output_target[1])) * 100, \"%\")\n",
        "print(\"Error rate for d:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[2] == bipolar_output_target[2])) * 100, \"%\")\n",
        "print(\"Error rate for l:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[3] == bipolar_output_target[3])) * 100, \"%\")\n",
        "print(\"Error rate for n:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[4] == bipolar_output_target[4])) * 100, \"%\")\n",
        "print()\n",
        "print(\"Total error rate for noisy bipolar patterns:\",(1-np.mean(predictions_for_noisy_bipolar_patterns == bipolar_output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For bipolar encoding, we found a slight increase in error, which may indicate robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Noisy patterns (25%)\n",
        "To insert 25% noise into the pattern, we must change about 16 cells in each pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_random = 16\n",
        "# Randomly choose 16 indices to change and add 25% noise to the patterns\n",
        "indices_to_change = np.zeros((len(patterns),number_of_random))\n",
        "for i in range(len(patterns)):\n",
        "    indices_to_change[i] = random.sample(range(len(patterns[0])), number_of_random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [],
      "source": [
        "noisy_patterns = patterns.copy()\n",
        "noisy_bipolar_patterns = bipolar_patterns.copy()\n",
        "\n",
        "for i in range(len(patterns)):\n",
        "    for j in range(number_of_random):\n",
        "        if noisy_patterns[i][int(indices_to_change[i][j])] == 1:\n",
        "            noisy_patterns[i][int(indices_to_change[i][j])] = 0\n",
        "        else:\n",
        "            noisy_patterns[i][int(indices_to_change[i][j])] = 1\n",
        "\n",
        "for i in range(len(patterns)):\n",
        "    for j in range(number_of_random):\n",
        "        if noisy_bipolar_patterns[i][int(indices_to_change[i][j])] == 1:\n",
        "            noisy_bipolar_patterns[i][int(indices_to_change[i][j])] = -1\n",
        "        else:\n",
        "            noisy_bipolar_patterns[i][int(indices_to_change[i][j])] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = noisy_patterns\n",
        "predictions_for_noisy_patterns = np.zeros((5,15))\n",
        "\n",
        "predictions_for_noisy_patterns[0] = neuron_b.predict(X_test)\n",
        "predictions_for_noisy_patterns[1] = neuron_c.predict(X_test)\n",
        "predictions_for_noisy_patterns[2] = neuron_d.predict(X_test)\n",
        "predictions_for_noisy_patterns[3] = neuron_l.predict(X_test)\n",
        "predictions_for_noisy_patterns[4] = neuron_n.predict(X_test)\n",
        "\n",
        "\n",
        "X_test = noisy_bipolar_patterns\n",
        "predictions_for_noisy_bipolar_patterns = np.zeros((5,15))\n",
        "\n",
        "predictions_for_noisy_bipolar_patterns[0] = bipolar_neuron_b.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[1] = bipolar_neuron_c.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[2] = bipolar_neuron_d.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[3] = bipolar_neuron_l.predict(X_test)\n",
        "predictions_for_noisy_bipolar_patterns[4] = bipolar_neuron_n.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 80.0 %\n",
            "Error rate for c: 80.0 %\n",
            "Error rate for d: 80.0 %\n",
            "Error rate for l: 80.0 %\n",
            "Error rate for n: 80.0 %\n",
            "\n",
            "Total error: 80.0 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Error rate for b:\",(1-np.mean(predictions_for_noisy_patterns[0] == target_b)) * 100, \"%\")\n",
        "print(\"Error rate for c:\",(1-np.mean(predictions_for_noisy_patterns[1] == target_c)) * 100, \"%\")\n",
        "print(\"Error rate for d:\",(1-np.mean(predictions_for_noisy_patterns[2] == target_d)) * 100, \"%\")\n",
        "print(\"Error rate for l:\",(1-np.mean(predictions_for_noisy_patterns[3] == target_l)) * 100, \"%\")\n",
        "print(\"Error rate for n:\",(1-np.mean(predictions_for_noisy_patterns[4] == target_n)) * 100, \"%\")\n",
        "print()\n",
        "print(\"Total error:\",(1-np.mean(predictions_for_noisy_patterns == output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Binary encoding still performs poorly in every state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error rate for b: 13.33333333333333 %\n",
            "Error rate for c: 0.0 %\n",
            "Error rate for d: 19.999999999999996 %\n",
            "Error rate for l: 13.33333333333333 %\n",
            "Error rate for n: 13.33333333333333 %\n",
            "\n",
            "Total error: 12.0 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Error rate for b:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[0] == bipolar_output_target[0])) * 100, \"%\")\n",
        "print(\"Error rate for c:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[1] == bipolar_output_target[1])) * 100, \"%\")\n",
        "print(\"Error rate for d:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[2] == bipolar_output_target[2])) * 100, \"%\")\n",
        "print(\"Error rate for l:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[3] == bipolar_output_target[3])) * 100, \"%\")\n",
        "print(\"Error rate for n:\", (1 - np.mean(predictions_for_noisy_bipolar_patterns[4] == bipolar_output_target[4])) * 100, \"%\")\n",
        "print()\n",
        "print(\"Total error rate:\",(1-np.mean(predictions_for_noisy_bipolar_patterns == bipolar_output_target)) * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For 25% noise in bipolar encoding, we see a slight increase in the error rate from 10% noise, but it still demonstrates robustness."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
